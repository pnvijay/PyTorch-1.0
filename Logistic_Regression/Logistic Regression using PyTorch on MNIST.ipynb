{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the Notebook\n",
    "This notebook is to showcase how you can use PyTorch for Logistic Regression. This notebook is inspired by the series \"PyTorch: Zero to GANs\" by Aakash NS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n",
      "0.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dataset from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MNIST has two sections - Train and Test\n",
    "### To download the train section we will pass the directory where data is to be downloaded, specify train=True\n",
    "### so that only train section is chosen and then specify download=True so that the download happens\n",
    "train = MNIST(root='data/',train=True,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Even if there is no directory called data, it will be created and train section will be downloaded\n",
    "### We will follow similar practice to download the test section. The only change will be that \n",
    "### we will specify train=False so that the test section is downloaded\n",
    "test = MNIST(root='data/',train=False,download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now downloaded. Let us now check the size of the downloaded train and test section of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x11A274198>, tensor(5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let us look into what the train section contains\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can see above that the first element in the train section contains an PIL Image in grayscale (mode=L)\n",
    "### and a label of type tensor. \n",
    "### Lets get both the values from the first element\n",
    "img,label = train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x11A274A58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let's see the image\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let's see the label. Since the label is a single tensor element, we will pass label.item() to see the value only\n",
    "label.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above the image is still in picture format. It has to be transformed to a Tensor if it has to be processed by PyTorch. Hence we will be doing the transformation to convert the same into a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.transform = tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "img,label = train[0]\n",
    "img\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We will apply the same to test and see the results\n",
    "test.transform = tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Train Dataset into Train and Validation Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded dataset is already a PyTorch Dataset type. So we can directly go and create the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the dataloaders, let's find a way to split the train dataset into a training and validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way is to use torch.utils.data.random_split and specify the split sizes on the dataset length. In the case below, I have specified out of total 60000 items in the dataset, 54000 items will be in train and 6000 will be in validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,val_ds = torch.utils.data.random_split(train,[int(len(train)*0.9),int(len(train)*0.1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the split has been performed well and we are able to retrieve the items in the split datasets below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.4471, 0.9333, 0.9922, 0.9922, 0.9922, 1.0000, 0.3529,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.4941, 0.9922, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9529,\n",
       "            0.3804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "            0.7961, 0.9922, 0.9882, 0.9373, 0.7647, 0.8902, 0.9922, 0.9882,\n",
       "            0.7647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.5490, 0.9922, 0.8863, 0.3765, 0.0000, 0.5490, 0.9922, 0.9882,\n",
       "            0.7647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "            0.7961, 0.7451, 0.0471, 0.0000, 0.0627, 0.7961, 0.9922, 0.9882,\n",
       "            0.7647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "            0.2471, 0.0000, 0.0000, 0.1020, 0.5020, 0.9922, 1.0000, 0.9922,\n",
       "            0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.1137, 0.4784, 0.9882, 0.9882, 0.9922, 0.8000,\n",
       "            0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.2235, 0.7843, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882,\n",
       "            0.8196, 0.4039, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.3725, 0.9922, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882,\n",
       "            0.9882, 0.9882, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.5490, 0.9922, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882,\n",
       "            0.9882, 0.9882, 0.7412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.5529, 1.0000, 0.9922, 0.6471, 0.1843, 0.0000, 0.0000, 0.1882,\n",
       "            0.8980, 0.9922, 0.9922, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.3686, 0.1059, 0.1059, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.2824, 0.9882, 0.9882, 0.9451, 0.0941, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.2235, 0.9882, 0.9882, 0.9922, 0.1059, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.2235, 0.9882, 0.9882, 0.9922, 0.1059, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.2235, 0.9882, 0.9882, 0.9922, 0.1059, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.4471, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000, 0.3961,\n",
       "            0.8706, 0.9922, 0.9922, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.9922, 0.9529, 0.8824, 0.8824, 0.5725, 0.8863, 0.9765,\n",
       "            0.9882, 0.9882, 0.9882, 0.3686, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.8706, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882,\n",
       "            0.9882, 0.9608, 0.7647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.1490, 0.5098, 0.9020, 0.9882, 0.9882, 0.9922, 0.9882,\n",
       "            0.9608, 0.4745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0980, 0.4392, 0.7412, 0.4392, 0.4392,\n",
       "            0.3412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000]]]), tensor(3)),\n",
       " (tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.1412, 0.6392, 0.6627, 0.9961, 0.7686,\n",
       "            0.3765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.4196, 0.9373, 0.9922, 0.9922, 0.9922, 0.9961,\n",
       "            0.9765, 0.5647, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.3098, 0.9961, 0.9922, 0.9686, 0.8471, 0.8471, 0.8941,\n",
       "            0.9922, 0.9922, 0.5647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.2039, 0.9961, 0.8980, 0.3608, 0.0000, 0.0000, 0.0627,\n",
       "            0.6157, 0.9804, 0.9765, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.9961, 0.8549, 0.1804, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.7255, 0.9922, 0.5333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.7686, 0.9961, 0.8510, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0549, 0.8588, 0.8667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.2510, 0.7020, 0.2353, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.7804, 0.9922, 0.2078, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0235, 0.8118, 0.9922, 0.3059, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.1686, 0.9922, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.0000,\n",
       "            0.0000, 0.5020, 0.9922, 0.6078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.3882, 0.9961, 0.8667, 0.9961, 0.9961, 1.0000,\n",
       "            0.9176, 0.8157, 0.9961, 0.2824, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.1176, 0.6941, 0.9686, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961,\n",
       "            0.9922, 0.9922, 0.9922, 0.4353, 0.3451, 0.0941, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.4275, 0.9922, 0.9961, 0.9608, 0.8706, 0.8784, 0.8471, 0.8510,\n",
       "            0.9804, 0.9922, 0.9922, 0.9922, 0.8510, 0.2353, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.4275, 0.9922, 0.8471, 0.3176, 0.0314, 0.0471, 0.0000, 0.1490,\n",
       "            0.9529, 0.9922, 0.9608, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.4275, 0.9922, 0.3569, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941,\n",
       "            0.9922, 0.9922, 0.5373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.4314, 0.9961, 0.4627, 0.0000, 0.0000, 0.0235, 0.4157, 1.0000,\n",
       "            0.9961, 0.9961, 0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0549, 0.7529, 0.9765, 0.5137, 0.2157, 0.5216, 0.9922, 0.9961,\n",
       "            0.9451, 0.4235, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.3569, 0.9961, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961,\n",
       "            0.7255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0784, 0.5608, 0.9922, 0.9922, 0.9922, 0.9922, 0.4667,\n",
       "            0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0824, 0.3608, 0.6863, 0.8392, 0.3843, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000]]]), tensor(2)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0],val_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is to use the SubsetRandomSampler from PyTorch. This is in the torch.utils.data.sampler section and takes in indices as values. It samples batch size of indices from the total indices provided without replacement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we will split the 60000 indices available in the train dataset randomly into two sets that contain 54000 and 6000. We will then provide these randomly split indices to the SubsetRandomSampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1232, 11667,  4020, ..., 34816, 26699, 56766])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We will randomly rearrange the 60000 indices using np.random.permutation\n",
    "### In the train dataset the indices are numbered in an ordered manner from 0 to 59999\n",
    "### We will generate a random order of indices which total 60000 in number but do not contain the orderliness\n",
    "### that was there before\n",
    "idx = np.random.permutation(len(train))\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 6000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### As you can see above the orderliness has now been disturbed\n",
    "train_indices = idx[:int(len(train)*0.9)]\n",
    "val_indices = idx[int(len(train)*0.9):]\n",
    "len(train_indices),len(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataloaders can now be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Please note that if you are using the sampler then Shuffle has to be False\n",
    "### Hence we are not shuffling the train or validation dataloader\n",
    "train_dl = torch.utils.data.DataLoader(train,batch_size=32,shuffle=False,\n",
    "                                       sampler=torch.utils.data.sampler.SubsetRandomSampler(train_indices))\n",
    "val_dl = torch.utils.data.DataLoader(train,batch_size=32,shuffle=False,\n",
    "                                       sampler=torch.utils.data.sampler.SubsetRandomSampler(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a very simple Model which is nothing but a Linear Layer. Loss function is cross entropy and Optimizer used is SGD with learning rate of 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(784,10)\n",
    "loss_fn = F.cross_entropy\n",
    "opt = torch.optim.SGD(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches in Train Data Loader is 1688\n",
      "Total number of batches in Validation Data Loader is 1688\n"
     ]
    }
   ],
   "source": [
    "## Total number of batches in Train and Validation Dataloaders\n",
    "print(\"Total number of batches in Train Data Loader is {}\".format(len(train_dl)))\n",
    "print(\"Total number of batches in Validation Data Loader is {}\".format(len(train_dl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Helper Functions for getting Accuracy per Batch, Loss Per Batch, Accuracy per Epoch and Loss Per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We take the output of the model, targets and batch_size\n",
    "## We take the softmax of the output to get the probabilities\n",
    "## The maximum of the probabilities is taken as the predicted label value\n",
    "## Accuracy is defined as number of predictions that equal the target values divided by the batch size\n",
    "def accuracy_batch(output,yb,batch_num):\n",
    "    probs = F.softmax(output,dim=1)\n",
    "    _,preds = torch.max(probs,dim=1)\n",
    "    acc_batch = torch.sum(preds==yb).item()/batch_num\n",
    "    return acc_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We take the loss function, input and target values\n",
    "## Input is resized from [1,28,28] to [batch_size,784] so as to flatten the values for processing\n",
    "## Loss is calculated by passing the loss function\n",
    "## Accuracy of the batch is calculated by calling the accuracy_batch function\n",
    "## Loss, Value of Loss, Accuracy of batch and batch size is returned\n",
    "def loss_batch(loss_fn,xb, yb):\n",
    "    output = model(xb.reshape(-1,784))\n",
    "    loss_bat = loss_fn(output,yb)\n",
    "    batch_num = len(xb)\n",
    "    acc_batch = accuracy_batch(output,yb,batch_num)\n",
    "    return loss_bat,loss_bat.item(),acc_batch,batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total Accuracy per Epoch is calculated by taking the accuracy per batch and \n",
    "## dividing by total number of batches\n",
    "def avg_accuracy(acc_batch,batch_num,total_batches):\n",
    "    avg_acc = np.sum(acc_batch)/total_batches\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total Loss per Epoch is calculated by taking the loss per batch and \n",
    "## dividing by total number of batches\n",
    "def avg_loss(loss_batch,batch_num,total_batches):\n",
    "    return np.sum(loss_batch)/total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We define a function that takes the number of epochs for training,model, \n",
    "## the dataloaders (train and validation) and the optimizer function\n",
    "def fit(epochs,model,loss_fn,train_dl,val_dl,opt):\n",
    "    ## Total number of batches for train and validation are found\n",
    "    num_bat_train = len(train_dl)\n",
    "    num_bat_val = len(val_dl)\n",
    "    ## Iterate training through the number of epochs\n",
    "    for i in range(epochs):\n",
    "        ## Capture the per batch accuracy, batch size, batch loss\n",
    "        avg_bat_loss = []\n",
    "        avg_bat_acc = []\n",
    "        avg_batch_n = []\n",
    "        ## Iterate through a complete epoch\n",
    "        for xb,yb in train_dl:\n",
    "            ## Get the loss per batch, loss value, accuracy per batch and batch size\n",
    "            loss,loss_bat,acc_batch,batch_num = loss_batch(loss_fn,xb,yb)\n",
    "            ## Append the above got values into a list defined at the start\n",
    "            avg_bat_loss.append(loss_bat)\n",
    "            avg_bat_acc.append(acc_batch)\n",
    "            avg_batch_n.append(batch_num)\n",
    "            ## Perform Gradient Descent and Optimization\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        ## Calculate the Accuracy and Loss per Epoch and print them\n",
    "        epoch_loss = avg_loss(avg_bat_loss,avg_batch_n,num_bat_train)\n",
    "        epoch_accuracy = avg_accuracy(avg_bat_acc,avg_batch_n,num_bat_train)\n",
    "        print(\"Training Epoch {}/{}, Loss is {:.4f}, Accuracy is {:.4f}\".format(i+1,epochs,epoch_loss,epoch_accuracy))\n",
    "        ## Perform the same process for validation dataset using validation dataloader\n",
    "        ## But we ask for the gradients not to be calculated and updated\n",
    "        val_loss = []\n",
    "        val_acc = []\n",
    "        batch_v = []\n",
    "        for img_v,label_v in val_dl:\n",
    "            with torch.no_grad():\n",
    "                img_v = img_v.reshape(-1,784)\n",
    "                loss_v,loss_vt,acc_bat_v,batch_num_v = loss_batch(loss_fn,img_v,label_v)\n",
    "                val_loss.append(loss_vt)\n",
    "                batch_v.append(batch_num_v)\n",
    "                val_acc.append(acc_bat_v)\n",
    "        avg_val_loss = avg_loss(val_loss,batch_v,num_bat_val)\n",
    "        avg_val_accuracy = avg_accuracy(val_acc,batch_v,num_bat_val)\n",
    "        print(\"Validation Epoch {}/{}, Loss is {:.4f}, Accuracy is {:.4f}\".format(i+1,epochs,\n",
    "                                                                                  avg_val_loss,avg_val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5, Loss is 1.6832, Accuracy is 0.6636\n",
      "Validation Epoch 1/5, Loss is 1.2801, Accuracy is 0.7960\n",
      "Training Epoch 2/5, Loss is 1.0885, Accuracy is 0.8108\n",
      "Validation Epoch 2/5, Loss is 0.9535, Accuracy is 0.8261\n",
      "Training Epoch 3/5, Loss is 0.8637, Accuracy is 0.8329\n",
      "Validation Epoch 3/5, Loss is 0.8042, Accuracy is 0.8384\n",
      "Training Epoch 4/5, Loss is 0.7478, Accuracy is 0.8454\n",
      "Validation Epoch 4/5, Loss is 0.7163, Accuracy is 0.8454\n",
      "Training Epoch 5/5, Loss is 0.6761, Accuracy is 0.8530\n",
      "Validation Epoch 5/5, Loss is 0.6604, Accuracy is 0.8492\n"
     ]
    }
   ],
   "source": [
    "fit(5,model,loss_fn,train_dl,val_dl,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5, Loss is 0.6268, Accuracy is 0.8584\n",
      "Validation Epoch 1/5, Loss is 0.6199, Accuracy is 0.8549\n",
      "Training Epoch 2/5, Loss is 0.5905, Accuracy is 0.8637\n",
      "Validation Epoch 2/5, Loss is 0.5898, Accuracy is 0.8549\n",
      "Training Epoch 3/5, Loss is 0.5625, Accuracy is 0.8671\n",
      "Validation Epoch 3/5, Loss is 0.5660, Accuracy is 0.8600\n",
      "Training Epoch 4/5, Loss is 0.5401, Accuracy is 0.8700\n",
      "Validation Epoch 4/5, Loss is 0.5463, Accuracy is 0.8627\n",
      "Training Epoch 5/5, Loss is 0.5217, Accuracy is 0.8727\n",
      "Validation Epoch 5/5, Loss is 0.5302, Accuracy is 0.8645\n"
     ]
    }
   ],
   "source": [
    "fit(5,model,loss_fn,train_dl,val_dl,torch.optim.SGD(model.parameters(),lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the Model state containing the weights and other information\n",
    "torch.save(model.state_dict(),'mnist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get a single item from the test dataset\n",
    "img,label = test[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add dimension to the image to add the batch size dimension\n",
    "## As seen above it is three dimensional shape but since the model performs on a batch\n",
    "## it should be converted to have another dimension that signifies the batch size\n",
    "img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7]) tensor(7)\n"
     ]
    }
   ],
   "source": [
    "## Predict the label and check with actual for the image\n",
    "## As is norm we will need to convert the input into a two dimensional shape\n",
    "preds = model(img.reshape(-1,784))\n",
    "probs = F.softmax(preds,dim=1)\n",
    "_,pred_label = torch.max(probs,dim=1)\n",
    "print(pred_label,label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PyTF]",
   "language": "python",
   "name": "conda-env-PyTF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
